{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, FunctionTransformer\n",
    "from src.gen import train_test_from_null, get_xy_from_dataframe\n",
    "from src.kaggle_api import get_dataset\n",
    "\n",
    "# Whether to run intensive grid searches (True) or simple fits (False)\n",
    "intensive = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = get_dataset(\"titanic\")\n",
    "raw_train_data = pd.read_csv(data_path / \"train.csv\")\n",
    "raw_test_data = pd.read_csv(data_path / \"test.csv\")\n",
    "raw_comb_data = pd.concat([raw_train_data, raw_test_data], ignore_index=True)\n",
    "\n",
    "print(raw_train_data.info())\n",
    "print(raw_test_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_title_old(df):\n",
    "    df[\"Title\"] = df[\"Name\"].str.extract(r\",\\s?(\\w*).{1}\")\n",
    "\n",
    "    replace_male = (df[\"Sex\"] == \"male\") & (~df[\"Title\"].isin([\"Mr\", \"Master\"]))\n",
    "    df.loc[replace_male, \"Title\"] = \"Mr\"\n",
    "    df.loc[replace_male & (df[\"Age\"] < 18), \"Title\"] = \"Master\"\n",
    "\n",
    "    replace_female = (df[\"Sex\"] == \"female\") & (~df[\"Title\"].isin([\"Miss\", \"Mrs\"]))\n",
    "    df.loc[replace_female, \"Title\"] = \"Miss\"\n",
    "    df.loc[replace_female & (df[\"Age\"] > 18) & (df[\"SibSp\"] | df[\"Parch\"]), \"Title\"] = \"Mrs\"\n",
    "    df[\"Title\"] = pd.factorize(df[\"Title\"])[0]\n",
    "\n",
    "    return df[[\"Title\"]]\n",
    "\n",
    "def get_title(df):\n",
    "    df[\"Title\"] = df[\"Name\"].str.extract(r\",\\s?(\\w*).{1}\")\n",
    "\n",
    "    is_male = df[\"Sex\"] == \"male\"\n",
    "    is_female = df[\"Sex\"] == \"female\"\n",
    "    outlier_male = is_male & (~df[\"Title\"].isin([\"Mr\", \"Master\"]))\n",
    "    df.loc[outlier_male, \"Title\"] = \"Mr\"\n",
    "\n",
    "    # All men under 18 = Master, over = Mr\n",
    "    df.loc[is_male & (df[\"Age\"] >= 18), \"Title\"] = \"Mr\"\n",
    "    df.loc[is_male & (df[\"Age\"] < 18), \"Title\"] = \"Master\"\n",
    "\n",
    "    outlier_female = is_female & (~df[\"Title\"].isin([\"Miss\", \"Mrs\"]))\n",
    "    df.loc[outlier_female, \"Title\"] = \"Mrs\"\n",
    "\n",
    "    # All women over 18 = Mrs, under = Miss\n",
    "    df.loc[is_female & (df[\"Age\"] >= 18), \"Title\"] = \"Mrs\"\n",
    "    df.loc[is_female & (df[\"Age\"] < 18), \"Title\"] = \"Miss\"\n",
    "    out = pd.get_dummies(df[\"Title\"], drop_first=True)\n",
    "    # df[\"Title\"] = pd.factorize(df[\"Title\"])[0]\n",
    "\n",
    "    return out # df[[\"Title\"]]\n",
    "\n",
    "age_target = \"age_bin\"\n",
    "age_bins = 5\n",
    "\n",
    "comb_data = raw_comb_data.copy()\n",
    "# comb_data = comb_data.assign(age_bin=pd.qcut(comb_data[\"Age\"], q=age_bins, precision=0, labels=False, retbins=False).values)\n",
    "comb_data = comb_data.assign(age_bin=pd.cut(comb_data[\"Age\"], bins=[-1, 17, 30, 50, np.inf], precision=0, labels=False, retbins=False).values)\n",
    "\n",
    "age_train_data, age_test_data = train_test_from_null(comb_data, age_target)\n",
    "y_age_train = age_train_data[age_target]\n",
    "\n",
    "clip_sibsp = FunctionTransformer(lambda x, kwargs: x.clip(**kwargs), kw_args={\"kwargs\": {\"upper\": 3}})\n",
    "clip_parch = FunctionTransformer(lambda x, kwargs: x.clip(**kwargs), kw_args={\"kwargs\": {\"upper\": 2}})\n",
    "\n",
    "age_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"pclass\", OrdinalEncoder(), [\"Pclass\"]),\n",
    "        (\"sibsp\", clip_sibsp, [\"SibSp\"]),\n",
    "        (\"parch\", clip_parch, [\"Parch\"]),\n",
    "        (\"title\", FunctionTransformer(get_title), [\"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "trans_train = age_preprocessor.fit_transform(age_train_data)\n",
    "trans_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This method also allows us to tune the preprocessing step by adding parameters to the hyperparameters search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipe_hyperparams = {\n",
    "#    \"preprocess__parch__kw_args\": [\n",
    "#        {\"kwargs\": {\"upper\": 1}},\n",
    "#        {\"kwargs\": {\"upper\": 2}},\n",
    "#        {\"kwargs\": {\"upper\": 3}},\n",
    "#    ],\n",
    "#    \"preprocess__sibsp__kw_args\": [\n",
    "#        {\"kwargs\": {\"upper\": 2}},\n",
    "#        {\"kwargs\": {\"upper\": 3}},\n",
    "#        {\"kwargs\": {\"upper\": 4}},\n",
    "#    ],\n",
    "    \"classifier__learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1],\n",
    "    \"classifier__min_samples_split\": np.linspace(0.1, 0.5, 4),\n",
    "    \"classifier__min_samples_leaf\": np.linspace(0.1, 0.5, 4),\n",
    "    \"classifier__max_depth\": [5, 8],\n",
    "    \"classifier__subsample\": [0.6, 0.8, 0.95, 1.0],\n",
    "}\n",
    "\n",
    "age_pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", age_preprocessor),\n",
    "    (\"classifier\", GradientBoostingClassifier(loss=\"log_loss\", criterion=\"friedman_mse\", n_estimators=50))]\n",
    ")\n",
    "\n",
    "if not intensive:\n",
    "    age_pipe.fit(age_train_data, y_age_train)\n",
    "    y_pred = age_pipe.predict(age_test_data)\n",
    "    disp = age_pipe\n",
    "else:\n",
    "    age_clf = GridSearchCV(age_pipe, param_grid=pipe_hyperparams, cv=10, n_jobs=-1, verbose=2)\n",
    "    age_clf.fit(age_train_data, y_age_train)\n",
    "    print(\"model score: %.3f\" % age_clf.best_score_)\n",
    "    y_pred = age_clf.predict(age_test_data)\n",
    "    disp = age_clf\n",
    "\n",
    "disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "age_test_data.loc[:, age_target] = y_pred\n",
    "\n",
    "comb_data = pd.concat([age_train_data, age_test_data]).sort_index()\n",
    "comb_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = \"Survived\"\n",
    "\n",
    "train_data, test_data = train_test_from_null(comb_data, target)\n",
    "_, y_train = get_xy_from_dataframe(train_data, target)\n",
    "\n",
    "embarked_transformer = make_pipeline(SimpleImputer(strategy=\"most_frequent\"), OneHotEncoder())\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"fare\", SimpleImputer(strategy=\"mean\"), [\"Fare\"]),\n",
    "        (\"Embarked\", embarked_transformer, [\"Embarked\"]),\n",
    "        (\"pclass_age\", OrdinalEncoder(), [\"Pclass\", \"age_bin\"]),\n",
    "        (\"sibsp\", clip_sibsp, [\"SibSp\"]),\n",
    "        (\"parch\", clip_parch, [\"Parch\"]),\n",
    "        (\"title\", FunctionTransformer(get_title), [\"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\"]),\n",
    "        #(\"cat\",         categorical_transformer, categorical_features)\n",
    "        #(\"cat\",         categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        #(\"num\",         numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_pro = preprocessor.fit_transform(train_data)\n",
    "X_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"classifier\", GradientBoostingClassifier(loss=\"log_loss\", criterion=\"friedman_mse\", n_estimators=50))]\n",
    ")\n",
    "\n",
    "if not intensive:\n",
    "    pipe.fit(train_data, y_train)\n",
    "    y_pred = pipe.predict(test_data)\n",
    "    disp = pipe\n",
    "else:\n",
    "    clf = GridSearchCV(pipe, param_grid=pipe_hyperparams, cv=10, n_jobs=-1, verbose=2)\n",
    "    clf.fit(train_data, y_train)\n",
    "    print(\"model score: %.3f\" % clf.best_score_)\n",
    "    y_pred = clf.predict(test_data)\n",
    "    disp = clf\n",
    "\n",
    "disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_data = test_data.copy()\n",
    "test_data[target] = y_pred\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get correct format\n",
    "test_data[target] = test_data[target].astype(int)\n",
    "\n",
    "# Write out\n",
    "test_data.to_csv(data_path / \"pipeline_prediction.csv\", columns=[\"PassengerId\", target], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is a good start, but we would like to only predict one thing in the dataset (survival), and encapsulate all preprocessing and classification within a single pipeline. To do this we need a smarter imputer method to fill the null Age rows. Options to move forward are:\n",
    "- Nest the current method within the pipeline (only if we can improve the current method)\n",
    "- Use the experimental iterative imputer provided by scikit-learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
