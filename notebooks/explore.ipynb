{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0048f47f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Thoughts:\n",
    "Age is a potentially high correlator, but many entries have null age. Could see what values correlate to age, and fit a model to predict null ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0042280",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.base import clone\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from dython.nominal import associations, identify_nominal_columns\n",
    "\n",
    "sys.path.append(\"/home/andrew/PycharmProjects/PyTorch\")\n",
    "from src.kaggle_api import get_dataset\n",
    "from src.estimator_comparison import test_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61326fb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load in dataset and show info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e15d260",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = get_dataset(\"titanic\")\n",
    "train_data = pd.read_csv(data_path / \"train.csv\")\n",
    "test_data = pd.read_csv(data_path / \"test.csv\")\n",
    "\n",
    "print(train_data.info())\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9f2f3b",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's also see how many rows contain null values, and the breakdown of these per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a02c3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def null_breakdown(df, name: str = \"\"):\n",
    "    tot_null = df.isna().any(axis=1).sum()\n",
    "    col_null = df.isna().sum()\n",
    "\n",
    "    print(f\"{name} dataset total number of null rows is {tot_null}\")\n",
    "    print(f\"Breakdown per column is: \\n{col_null}\")\n",
    "\n",
    "null_breakdown(train_data, \"Training\")\n",
    "null_breakdown(test_data, \"Testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc9ecb",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Most of the missing values across both training and test datasets come from Cabin and Age. Let's combine the datasets and inspect further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c27a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comb_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "print(comb_data['Cabin'].value_counts())\n",
    "print(comb_data['Age'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0a89cd",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Both factors may correlate to survivability, but with so many missing Cabin entries it makes sense to remove it for now.\n",
    "NOTE: Strip Cabin to letter only and see if there's a correlation/connection between fare/class/cabin/ticket, it may be that lower class cabins are not recorded etc.\n",
    "\n",
    "Before removing the Cabin column, let's inspect some other columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224db5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(comb_data[\"Ticket\"].value_counts())\n",
    "comb_data[[\"Ticket\", \"Name\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227bf0ca",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The Ticket column is very messy and contains duplicates, so it is unlikely that much can be obtained from it, and surely there is no correlation between name and survival!\n",
    "\n",
    "But what about a correlation between name (or more specifically title) and age? This could be a useful predictor, let's try and extract titles using regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d5a6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#print(list(comb_data[\"Name\"]))\n",
    "comb_data[\"Title\"] = comb_data[\"Name\"].str.extract(r\",\\s?(\\w*).{1}\")\n",
    "comb_data[\"Title\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720969cc",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "That worked well! There's just a few outliers to work with. Some of these can be rectified easily by looking at the \"Sex\" column, for example a male with the title Dr or Rev can be called \"Mr\" for our purposes. Others will require a little more thought:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30605a76",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comb_data = comb_data.assign(Title=None)\n",
    "\n",
    "replace_male = (comb_data[\"Sex\"] == \"male\") & (~comb_data[\"Title\"].isin([\"Mr\", \"Master\"]))\n",
    "comb_data.loc[replace_male, \"Title\"] = \"Mr\"\n",
    "comb_data.loc[replace_male & (comb_data[\"Age\"] < 18), \"Title\"] = \"Master\"\n",
    "\n",
    "replace_female = (comb_data[\"Sex\"] == \"female\") & (~comb_data[\"Title\"].isin([\"Miss\", \"Mrs\"]))\n",
    "comb_data.loc[replace_female, \"Title\"] = \"Miss\"\n",
    "comb_data.loc[replace_female & (comb_data[\"Age\"] > 18) & (comb_data[\"SibSp\"] | comb_data[\"Parch\"]), \"Title\"] = \"Mrs\"\n",
    "\n",
    "print(comb_data[\"Title\"].value_counts())\n",
    "comb_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed3d5d",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, there are a couple of null values left outside the Age column, so let's fill them with reasonable values.\n",
    "\n",
    "TODO: This should be done separately for train and test, build a preprocessing pipeline and apply to both individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dafcab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fill = [\"Fare\", \"Embarked\"]\n",
    "comb_data[\"Fare\"] = comb_data[\"Fare\"].fillna(comb_data[\"Fare\"].mean())\n",
    "comb_data[\"Embarked\"] = comb_data[\"Embarked\"].fillna(comb_data[\"Embarked\"].mode())\n",
    "\n",
    "comb_data.reset_index(drop=True)\n",
    "comb_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e17359d",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is our baseline database to predict both passenger age and survival. It currently contains span both training and test datasets, since we want to use as much data as possible to build the age model.\n",
    "\n",
    "First, let's look at age, dropping unnecessary columns:\n",
    "TODO: Explain why each is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb815ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "age_data = comb_data.copy()\n",
    "age_data = age_data.drop([\"PassengerId\", \"Cabin\", \"Ticket\", \"Name\", \"Survived\", \"Fare\", \"Embarked\", \"Sex\"], axis=1)\n",
    "age_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a9fe9f",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We are going to need to encode our Title column to numeric values, let's do that first:\n",
    "NOTE is this appropriate? One-hot encode instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042cc10",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "age_data[\"Title\"] = pd.factorize(age_data[\"Title\"])[0]\n",
    "age_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa76454d",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's look at each feature individually now with respect to age:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1ab1f8",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can have a look at how our columns correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc5f0c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "age_data.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4cb59",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It looks like Title does in fact have a high correlation to Age! Let's have a more visual look at this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9580965",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assoc_func = lambda data, nom_col: associations(\n",
    "    data,\n",
    "    nominal_columns=nom_col,\n",
    "    numerical_columns=None,\n",
    "    mark_columns=False,\n",
    "    nom_nom_assoc=\"cramer\",\n",
    "    num_num_assoc=\"pearson\",\n",
    "    cramers_v_bias_correction=False,\n",
    "    nan_strategy=\"drop_samples\",\n",
    "    ax=None,\n",
    "    figsize=None,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap=None,\n",
    "    sv_color='silver',\n",
    "    cbar=True,\n",
    "    vmax=1.0,\n",
    "    vmin=None,\n",
    "    plot=True,\n",
    "    compute_only=False,\n",
    "    clustering=False,\n",
    "    title=None,\n",
    "    filename=None\n",
    ")\n",
    "\n",
    "correl = assoc_func(age_data, \"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ce0be8",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's try again, this time specifying categorical columns. Also, we can now drop the Sex column, since it is fully correlated with Title which gives more information with respect to age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893d493",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = identify_nominal_columns(age_data)\n",
    "print(cat_cols)\n",
    "\n",
    "nom_col = [\"Pclass\", \"Title\"]\n",
    "assoc_func(age_data, nom_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a8a2c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "age_target = \"Age\"\n",
    "features = [c for c in age_data.columns if c != age_target]\n",
    "print(features)\n",
    "\n",
    "for f in features:\n",
    "    g = sns.FacetGrid(age_data, col=f)\n",
    "    g.map_dataframe(sns.histplot, x=age_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbafdd5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data becomes very sparse with increasing SibSp and Parch, so let's combine higher numbers\n",
    "NOTE how about combining features overall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f3f1a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "age_data[\"SibSp\"] = age_data[\"SibSp\"].clip(upper=3)\n",
    "age_data[\"SibSp\"] = age_data[\"Parch\"].clip(upper=2)\n",
    "\n",
    "for f in features:\n",
    "    g = sns.FacetGrid(age_data, col=f)\n",
    "    g.map_dataframe(sns.histplot, x=age_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e2632",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For some (ALL?) regressors we have to provide numeric values, so let's convert categorical data to one-hot vectors. We will also return k-1 columns since all 0's in a row will point to the baseline category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979c767",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# age_data_numerical = pd.get_dummies(age_data, columns=[\"Title\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4a962",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We don't need age to be predicted precisely to the number, rather we could simplify our model if we turned our current continuous age range regression problem into an age band classification problem.\n",
    "\n",
    "To do this, we have to band or \"bin\" our existing age data. We do not want to define these bands arbitrarily, however a reasonable starting point would be to band them in terms of frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f33cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bins = 5\n",
    "# age_group_labels = [f\"Group{i}\" for i in range(bins)]\n",
    "age_data[\"Age\"], bin_bounds = pd.qcut(age_data[\"Age\"], q=bins, precision=0, labels=False, retbins=True)\n",
    "\n",
    "age_bins = {i: bin_bounds[i:i+2] for i, k in enumerate(bin_bounds)}\n",
    "print(age_bins)\n",
    "age_data[\"Age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd4aafb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, let's split the age dataset into train and test based on which rows do not have age specified. Then we can start making predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b27a79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_from_null(df, target):\n",
    "\n",
    "    train_data = df.dropna(subset=target)\n",
    "    test_data = df[~df.index.isin(train_data.index)]\n",
    "    # Remove target from test data\n",
    "    test_data = test_data.drop(columns=target, errors=\"ignore\")\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "train_age_data, test_age_data = train_test_from_null(age_data, age_target)\n",
    "\n",
    "print(train_age_data)\n",
    "y_age = train_age_data[age_target]\n",
    "X_age = train_age_data[[c for c in train_age_data.columns if c != age_target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0252ef1-ae9c-438e-8dca-6ef17cde747e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "candidate_models = [\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    AdaBoostClassifier()\n",
    "]\n",
    "\n",
    "test_estimators(X_age, y_age, models=candidate_models, type_filter=\"classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71efdc1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "hyperparams = {\n",
    "    \"criterion\": ['gini', 'entropy'],\n",
    "    \"max_depth\": range(2, 16),\n",
    "    \"min_samples_split\": range(2, 10),\n",
    "    \"min_samples_leaf\": range(1, 5)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "clf = GradientBoostingClassifier(loss=\"log_loss\", criterion=\"friedman_mse\", n_estimators=50)\n",
    "\n",
    "hyperparams = {\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 4),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 4),\n",
    "    \"max_depth\": [5, 8],\n",
    "    \"subsample\":[0.6, 0.8, 0.95, 1.0],\n",
    "}\n",
    "\n",
    "model = GridSearchCV(clf, param_grid=hyperparams, cv=10, n_jobs=-1, verbose=2)\n",
    "model = model.fit(X_age, y_age)\n",
    "\n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "\n",
    "pred_age = model.predict(test_age_data)\n",
    "\n",
    "pred_data = test_age_data.copy()\n",
    "pred_data = pred_data.assign(Age=pred_age)\n",
    "\n",
    "all_age_data = pd.concat([train_age_data, pred_data], ignore_index=True)\n",
    "all_age_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444a984",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Great! We have our age predictions, now let's go back to our baseline dataset and make another copy for our survival prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2751d902",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "survive_data = comb_data.copy()\n",
    "survive_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddfc18a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's fill the age column, clip the SibSp and Parch columns again, and re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e409fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "survive_data = survive_data.drop([\"PassengerId\", \"Cabin\", \"Ticket\", \"Name\", \"Sex\"], axis=1)\n",
    "survive_data[\"Title\"] = pd.factorize(survive_data[\"Title\"])[0]\n",
    "survive_data[\"Embarked\"] = pd.factorize(survive_data[\"Embarked\"])[0]\n",
    "survive_data[\"SibSp\"] = survive_data[\"SibSp\"].clip(upper=3)\n",
    "survive_data[\"SibSp\"] = survive_data[\"Parch\"].clip(upper=2)\n",
    "survive_data[\"Age\"] = all_age_data[\"Age\"]\n",
    "survive_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab227649",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = \"Survived\"\n",
    "features = [c for c in survive_data.columns if c != target]\n",
    "\n",
    "train_survive_data, test_survive_data = train_test_from_null(survive_data, target)\n",
    "\n",
    "y = train_survive_data[target]\n",
    "X = train_survive_data[[c for c in train_survive_data.columns if c != target]]\n",
    "\n",
    "train_survive_data.info()\n",
    "test_survive_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e9779",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_estimators(X, y, models=candidate_models, type_filter=\"classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113969a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(test_survive_data)\n",
    "clf2 = clone(clf)\n",
    "\n",
    "model2 = GridSearchCV(clf2, param_grid=hyperparams, cv=10, n_jobs=-1, verbose=2)\n",
    "model2 = model2.fit(X, y)\n",
    "print(\"Best score: %0.3f\" % model2.best_score_)\n",
    "\n",
    "pred_survive = model2.predict(test_survive_data)\n",
    "\n",
    "pred_survive_data = test_survive_data.copy()\n",
    "pred_survive_data = pred_survive_data.assign(Survived=pred_survive).reset_index(drop=True)\n",
    "pred_survive_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa8f91",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Last but not least, we must save our prediction in csv format, providing only passenger ID and binary survive columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7fad35",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get correct format\n",
    "output = pred_survive_data.copy()\n",
    "output.index += train_data.shape[0] + 1\n",
    "output[target] = output[target].astype(int)\n",
    "\n",
    "# Write out\n",
    "output.to_csv(data_path / \"prediction.csv\", columns=[target], index=True, index_label=\"PassengerId\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyt] *",
   "language": "python",
   "name": "conda-env-pyt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
